{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy\n",
    "import numpy\n",
    "#시그모이드 함수\n",
    "import scipy.special\n",
    "#매트플롯\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    \n",
    "    #신경망 초기화\n",
    "    def __init__(self,inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        \n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        \n",
    "        #가중치 행력 wih who\n",
    "        self.wih  = numpy.random.normal(0.0, pow(self.hnodes,-0.5), (self.hnodes,self.inodes))\n",
    "        self.who  = numpy.random.normal(0.0, pow(self.onodes,-0.5), (self.onodes,self.hnodes))\n",
    "\n",
    "        #학습률\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        #활성화 함수로는 시그모이드 함수 이용\n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        #입력 리스트를 2차원의 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #은닉 계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih,inputs)\n",
    "        \n",
    "        #은닉계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "   \n",
    "        #최종 출력계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        #최종 출력계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        #오차는 (실제 값 - 계산 값)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        #은닉계층의 오차는 가중치에 의해 나뉜 출력 계층의 오차들을 재조합해 계산\n",
    "        hidden_errors = numpy.dot(self.who.T , output_errors)\n",
    "    \n",
    "    \n",
    "        #은닉 계층과 출력 계층간의 가중치 업데이트\n",
    "        self.who += self.lr*numpy.dot((output_errors*final_outputs*(1.0-final_outputs)),numpy.transpose(hidden_outputs))\n",
    "    \n",
    "    \n",
    "        #입력 계층과 은닉 계층간의 가중치 업데이트\n",
    "        self.wih += self.lr*numpy.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)),numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        #입력 리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #은닉계층으로 들어오는 신호를 계산\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        #은닉계층에서 나가는 신호를 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #최종 출력계층으로 들어오는 신호를 계산\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        #최종 출력계층에서 나가는 신호를 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = neuralNetwork(3,3,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5469198 ],\n",
       "       [ 0.38465509],\n",
       "       [ 0.41917198]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1,1,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = open(\"./TestData/mnist_train_100.csv\",'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x217bfd5f2b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x217bfce3d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[0].split(',') \n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28)) \n",
    "matplotlib.pyplot.imshow(image_array, cmap = 'Greys', interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.49141176  0.99223529\n",
      "  1.          0.25458824  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.38270588  0.95729412\n",
      "  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.50305882\n",
      "  0.98447059  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.274\n",
      "  0.92623529  0.98447059  0.82917647  0.13035294  0.04105882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.24294118\n",
      "  0.89517647  0.98447059  0.98447059  0.37494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.61176471  0.99223529  0.99223529  0.74376471  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.08764706  0.99223529  0.98447059  0.92235294  0.26623529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.80588235  0.99223529  0.98447059  0.49917647  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.41376471  0.98447059  0.99223529  0.72435294  0.06823529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32058824  0.94176471  0.98447059  0.75929412  0.09929412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.99223529  0.99223529  0.99223529  0.62729412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.59623529  0.98447059  0.98447059  0.98447059  0.16141176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.868       0.98447059  0.98447059  0.67776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.91847059  0.98447059  0.98447059  0.77094118  0.05658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.99223529  0.98447059  0.98447059  0.35552941  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.62729412  1.          0.99223529  0.99223529  0.13035294  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.89517647  0.99223529  0.96894118  0.55352941  0.04105882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.10317647  0.75929412  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 출력 노드는 10\n",
    "onodes = 10\n",
    "targets = numpy.zeros(onodes) + 0.01\n",
    "targets[int(all_values[0])] =0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_file = open(\"./TestData/mnist_train_100.csv\",'r')\n",
    "training_data_list = train_data_file.readlines()\n",
    "train_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for record in training_data_list:\n",
    "    #레코드를 쉼표에 의해 분리\n",
    "    all_values = record.split(',')\n",
    "    #입력값의 범위와 값 조정\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    #결과값 생성 ( 실제값인 0.99 이외에는 모두 0.01)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    #all_values[0]은 이 레코드에 대한 결과 값\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_file = open(\"./TestData/mnist_test_10.csv\",'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_values = test_data_list[1].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(all_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x217bfe86f98>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x217bfd655c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28)) \n",
    "matplotlib.pyplot.imshow(image_array, cmap = 'Greys', interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0848794 ],\n",
       "       [ 0.02913424],\n",
       "       [ 0.05680631],\n",
       "       [ 0.27795249],\n",
       "       [ 0.00288511],\n",
       "       [ 0.02780871],\n",
       "       [ 0.1754852 ],\n",
       "       [ 0.00281911],\n",
       "       [ 0.05329183],\n",
       "       [ 0.00342282]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
